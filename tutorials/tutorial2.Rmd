---
title: 'Roteiro 2'
author: "Melina Leite"
date: "Departamento de Ecologia IB-USP"
output:
  rmdformats::readthedown:
    highlight: kate
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, echo = F, message = F, cache = F}
knitr::opts_chunk$set(comment = NA, results = 'hide', message = FALSE, eval=FALSE, cache=FALSE, warning=FALSE)

#global options que vieram no rmdformats de html
library(knitr)
library(rmdformats)
options(max.print="75")
opts_knit$set(width=75)
```
```{r, echo=F}
setwd("/Users/melinatarituba/git-meme/consultR/tutorials")
```

Neste roteiro passaremos novamente em alguns tópicos de leitura, manipulação e transformação de dados. Logo após, trataremos de estatísticas descritivas e gráficos exploratórios.  Por fim, veremos algumas formas de elaborar gráficos para apresentação de resultados.

# Importando e verificando os dados

Baixe os arquivos de dados [ilhas](https://www.dropbox.com/s/mz0omdb3qhfv282/ilhas.csv?dl=0) e [sps](https://www.dropbox.com/s/3jupvtct55827vx/sps.csv?dl=0) e faça a leitura deles no R:
```{r}
ilhas <- read.csv2("../data/ilhas.csv",header=T,row.names = 1)
ilhas <- as.matrix(ilhas)
sps <- read.csv2("../data/sps.csv",header=T, dec=".")
```

A tabela `ilhas` é uma matriz da abundância de espécies (linhas) em diferentes ilhas (colunas). Quando importamos dados com as funções da família `read.table`, os objetos criados são sempre da classe `data frame`, por isso a necessidade de transformar o objeto em matriz.

A tabela `sps` é um data frame contendo as informações de atributos das mesmas espécies presentes em `ilhas`.

## Verificação dos dados

Após a importação precisamos verifica se a tabela foi importada corretamente, e se há erros na tabela. Em data frames costumamos utilizar a função `str` para ver a estrutura do objeto, mas em matrizes esta função não é tão útil.
```{r}
str(sps)
str(ilhas) #função não muito útil para matrizes
```

Se algo não parece correto quando você olha a tabela importada, é muito provável que tenha havido um erro de importação. Verifique novamente a sua tabela de dados e os argumentos da função de leitura de dados, principalmente `sep`, `header`, `dec` e `rown.names`.

A função `summary` também é bem útil em dada frames para verificação de dados.
```{r}
summary(sps)
```

Percebemos que existe um erro de digitação em `dieta`, há uma linha em que o nível `frutos` está escrito sem plural `fruto`. Abaixo veremos como consertar este erro.


## Corrigindo erros em data frames 

Há diferentes formas de se corrigir erros em vetores, data frames e matrizes. Abaixo, veremos um exemplo de como consertar erros de digitação em variáveis categóricas (fatores ou caracteres) usando indexação de data frames.

Primeiro vamos descobrir onde está o erro na variável `dieta` do data frame `sps`:
```{r}
# descobrindo em qual linha o nível de frutos está errado:
sps[ sps$dieta == "fruto" , ] # linha 9

# atribuindo à linha 9, coluna 4 a palavra frutos (correta)
sps[9, 4] <- "frutos"

#verificando a correção:
sps[9, ]

# podemos fazer os passos acima de maneira mais direta:
sps[ sps$dieta == "fruto" , 4] <- "frutos"
```

Vejamos o que aconteceu com a variável `dieta`:
```{r}
sps$dieta #classe de fatores 4 níveis

# contando quantos dados de cada nível
table(sps$dieta)
# veremos a função table mais abaixo
```

Como `dieta` é um fator, o nível "errado" `fruto` permanece na contagem dos fatores. Uma forma de re-arranjar a variável para conter apenas os 3 níveis corretos é transformar a variável em classe `character` e depois retransformar em `factor`:

```{r}
sps$dieta<- as.character(sps$dieta)
sps$dieta<- as.factor(sps$dieta)
sps$dieta
```


## Organizando data frames: `sort`, `order`, `rank`

 As três funções `sort`, `order` e `rank`são relacionadas, porém fazem coisas diferentes e é preciso prestar atenção. Baixe o arquivo [houses.txt](https://www.dropbox.com/s/cxk4fg6xr023jpn/houses.txt?dl=0) e carregue ele no R. Vamos ver a diferença entre as funções na prática:
 
```{r}
houses<-read.table("../data/houses.txt",header=T)
houses

ranks <- rank(houses$Price)
sorted <- sort(houses$Price)
ordered <- order(houses$Price)

view <- data.frame(houses$Price,ranks,sorted,ordered)
view
```

A função `rank` retorna a posição do ranking que aquele preço está. Como o vetor `Price` tem 12 números, o preço mais alto (325) vai ter o maior valor (12), e o preço mais baixo (95) o menor valor, 1. Os rankings fracionados indicam empate, por exemplo existem dois preços de 188, seus rankings seriam 8 e 9, como estão empatados a função atribuiu 8.5 a ambos.

A função `sort` é a mais intuitiva, ela ordena os preços do menor para o maior, ou do maior para o menor se você usar o argumento `decreasing=TRUE`. Porém, pode ser uma função perigosa, porque se você a usa em uma coluna de um data frame, ela poderá desacoplar a coluna sendo ordenada das demais colunas. Ou seja, você só mudará a coluna em questão deixando todo o data frame inalterado, o que fará perder a conexão entre os dados das linhas e as variáveis nas colunas.

A função `order` pode ser considerada a mais importante e um pouco menos intuitiva. Veja os números na coluna `odered`, eles também estão numerados de 1 a 12 como em `ranks`, porém eles querer dizer algo bem diferente. O primeiro valor (9) é número da linha em que o menor valor (95) se encontra. O segundo valor (6) é o número da linha em que o segundo menor valor (101) se encontra, e assim por diante. Observe novamente o objeto `view` e tente entender a lógica de `order`.

A função `order` é particularmente útil na ordenação de data frames inteiros através da indexação. Veja o exemplo:
```{r}
#ordenando houses em função do preço, perceba que a coluna Location também muda
houses[order(houses$Price), ]

# veja a diferença se eu usar a função sort
houses$Price <- sort(houses$Price)
houses 
# OPS! bagunçou o data frame!
```

Se você quiser ordenar o data frame por uma coluna de maneira decrescente, utilize o argumento `decreasing=TRUE` da função `order`. Essa função é relativamente boa quando queremos exportar uma tabela de dados/resultados para apresentar em relatórios/apresentações/artigos. Assim, você ordena o data frame pela coluna que você achar mais importante na hora de apresentar seus dados/resultados.


# Análise exploratórioa de dados

Podemos pensar a análise exploratória de dados de duas maneiras;

* Análise numérica: computando as estatísticas descritivas dos dados

* Análise gráfica: explorando o comportamento e a relação entre as variáveis através de gráficos.

Ambas são MUITO importantes para que possamos entender nosso dados, conhecer suas características e podermos faze as análises estatísticas mais apropriadas em um segundo passo. É nesta fase que estudamos a distribuição dos dados, observamos as premissas de normalidade e homogeneidade, encontramos possíveis dados atípicos (_outliers_), e analisamos graficamente a relação entre as nossas variáveis de interesse.

## Estatísticas descritivas

Como vimos no roteiro 1, listamos as principais estatísticas de resumo dos dados e suas funções no R. Vejamos os exemplos com os dados de `sps`:

```{r}
max(sps$compr.asa) # máximo
min(sps$compr.corpo) # mínimo

range(sps$peso) # máximo e mínimo

mean(sps$peso) # média
sd(sps$peso) # desvio padrão
var(sps$peso) # variância

median(sps$peso) # mediana
quantile(sps$peso) # quantil
```

Muitas das funções acima estão reunidas na função `summary`:
```{r}
summary(sps$peso) # sumário
```

### Quantis
Muitas das estatísticas acima são conhecidas de vocês, mas uma que geralmente é mais difícil de interpretar e entender é o **quantil**. A **mediana** é um quantil onde dividimos o conjunto de dados em 50%. Ou seja, 50% dos teus dados estão para a esquerda e 50% para a direita daquele valor. Vejamos um exemplo

```{r}
valores
```


O padrão da função `quantile` são os quartis, ou seja, são os valores das probabilidades em 25%, 50% e 75% (que é o mesmo retornado na função `summary`). Mas podemos mudar para qualquer quantil desejado:
```{r}
quantile(valores, probs = seq(from = 0, to = 1, by = 0.1))
```



<!-- PROCURAR EXEMPLO E EXPLICAÇÕES NO LIVRO DO MORETIN PARA ESSA SEÇÃO -->





## Descrevendo as observações - Contagens

A forma mais simples de descrever quantitativamente observações qualitativas é agrupá-las em categorias e contar quantas observações pertence a cada categoria.

No R a forma mais direta de obter contagens (frequências) é através da função `table.` Tomando como exemplo o data frame `sps`, podemos nos perguntar quantas espécies existem por dieta:

```{r}
table(sps$dieta)
```

A função `table` muito é útil para **variáveis categóricas** (classe de fatores ou caracteres). Vamos ver agora quantas espécies existem em uma combinação de dieta e cor:

```{r}
table(sps$dieta,sps$cor)
```

## Funções tapply e aggregate

Em `data frames`, quando temos uma variavel categórica (fator) e uma numérica, as funções `aggregate` e `tapply` são muito úteis. Estas funções aplicam uma função qualquer a uma variável quantitativa para cada classe de variável categórica.

A função `tapply` vai criar uma tabela com os resultados da função que você aplicou ao seu `data frame`. Por exemplo, queremos saber o comprimento médio do corpo das espécies por dieta, pois achamos que os bichos que tem uma dieta nectarívora sejam menores:

```{r}
#Comprimento médio do corpo por dieta
tapply(X = sps$compr.corpo, INDEX = sps$dieta, FUN = mean)
```

Entendendo os argumentos da função:  
- em `X` colocamos a variável quantitativa que estamos interessados em saber  
- em `INDEX` colocamos a(s) variável(is) qualitativa(s) que queremos resumir  
- em `FUN` colocamos a função que queremos aplicar na variável quantitativa, por exemplo `mean`, `max`, `min`, `var`.
  
Experimente este outro exemplo que separa o peso máximo das espécies por cor e dieta:
```{r}
tapply(sps$peso, list(sps$cor, sps$dieta), max)
```

Qual é a classe do objeto que resulta da função `apply`?

A função `aggregate` é o equivalente das tabelas dinâmicas das planilhas eletrônicas. Por exemplo, para obter do objeto `sps` um `data frame` com a abundância média das espécies por dieta e cor você executa o comando: 

```{r}
aggregate(formula = abund ~ cor + dieta, data = sps, FUN = mean)
```

Na função `aggregate` você pode inserir as variáveis através de fórmula ou como na função `tapply` indicando a variável quantitataiva a ser analisada e a variável categórica de interesse. A fórmula permite visualizar mais facilmente o que estamos fazendo. No exemplo acima queremos ver o sumário da abundância média das espécies por cor e dieta.

Em `aggregate` podemos também escolher mais de uma variável quantitativa como resultado. Veja o exemplo abaixo:

```{r}
# Abundância e peso médio por cor e dieta
aggregate(cbind(abund, peso) ~ cor+ dieta, sps, mean)
```

**OBS** Certifique-se que você entende a diferença entre as funções `aggregate` e `tapply` principalmente em relação ao tipo de saída (resultado) da função. Pense em quais situações seria melhor usar cada uma destas funções.

## Função `apply`

A função `apply` é utilizada matrizes, tem o objetivo de aplicar uma função nas linhas ou colunas da matriz. Por exemplo, na matriz `ilhas` queremos saber quantos bichos foram coletados por ilha:
```{r}
apply(X=ilhas, MARGIN=2,FUN=sum)
```

Ou então queremos saber qual a abundância média das espécies em cada ilha:
```{r}
apply(X=ilhas, MARGIN=1,FUN=mean)
```

O argumento `MARGIN` é quem diz se você aplicará a função por linha (1) ou coluna (2). 


# Gráficos exploratórios

O R é um ambiente de trabalho onde a análise gráfica de dados é de fácil execução. Entretanto, é necessário diferenciar dois tipos de gráficos:

- **Gráficos para análise de dados**: são gráficos simples que permitam visualizar o mais claro possível padrões presentes nos dados. Esses gráficos são construídos rapidamente no R e as formas de construí-los permitem inúmeras interações com os elementos de informação nos gráficos.  
- **Gráficos prontos para apresentação**: são construídos para inclusão em documentos e trabalhos técnicos e científicos, como forma de ilustrar resultados e conclusões. Gráficos de apresentação são mais elaborados. Sua construção no R exige mais tempo e conhecimento, pois o R não oferece recursos interativos para manipular os elementos pictoriais dos gráficos. Veremos sobre estes gráficos mais adiante no roteiro.  

Analisar um gráfico é uma maneira rápida e concisa de visualizar certas informações contidas em um conjunto de observações. O gráfico certo a ser utilizado em cada situação depende da informação que queremos visualizar e do tipo de variável que estamos trabalhando. Um gráfico mal elaborado muitas vezes falha em trazer com clareza a informação que queremos visualizar e, em alguns casos, pode levar a falsas evidências.


## O quarteto de Anscombe

Para ilustrar a importância de se fazer a análise  visual dos seus dados, colocamos um exemplo clássico de conjunto de dados com características completamente distintas, mas que resultam nos mesmos resultados de análises estatísticas - o [**Quarteto de Anscombe**](https://pt.wikipedia.org/wiki/Quarteto_de_Anscombe). Se não olhássemos a "cara" dos dados antes de analisar, poderíamos tirar conclusões errôneas baseadas apenas nos resultados das análises.  
Abaixo estão os 4 conjutos de dados:

```{r}
# o R já possui em seu pacote base os dados:
help("anscombe")

# para carregá-lo em sua área de trabalho:
data(anscombe)
```

Esse objeto é composto de 4 pares de variáveis: x1 a x4 (variáveis independentes ou preditoras) e y1 a y4 (variáveis depententes ou resposta).

```{r}
#média das colunas
media <-apply(ans, 2, mean)
media
# desvio padrão das colunas
desv.pad <-apply(ans, 2, sd)
desv.pad
```

Todos os quatro conjunto de dados são idênticos quanto às suas propriedades estatísticas (média, variância, correlação, coeficientes de regressão), mas variam consideravelmente quando graficados.

```{r}
#plotando os gráficos das relações entre x e y
par(mfrow=c(2,2) ,pch=16) # parâmetro gráfico

# conjunto dados 1
plot(anscombe$y1~anscombe$x1, col="red", xlab="x1", ylab="y1")
abline(a=3,b=0.5,col="blue")
title("Regressão: y=3+0.5x") # valores da regressão linear

# conjunto dados 2
plot(anscombe$y2~anscombe$x2,col="red",xlab="x2", ylab="y2")
abline(a=3,b=0.5,col="blue")
title("Regressão: y=3+0.5x") 

#conjunto dados 3
plot(anscombe$y3~anscombe$x3,col="red", xlab="x3", ylab="y3")
abline(a=3,b=0.5,col="blue")
title("Regressão: y=3+0.5x") 

#conjunto dados 4
plot(anscombe$y4~anscombe$x4, col="red",xlab="x4", ylab="y4")
abline(a=3,b=0.5,col="blue")
title("Regressão: y=3+0.5x") 
```



## Gráficos: Uma variável

O primeiro passo da análise gráfica dos dados é fazer gráficos para cada variável separadamente. Neste gráficos podemos analisar a distribuição das variáveis quantitativas, verificar a presença de _outliers_ (dados atípicos), e também observar a distribuição de frequência das variáveis qualitativas (categóricas). 



### Gráficos de barra

Gráficos de barras são geralmente utilizados para representar as quantitades de alguma variáveis qualitativas (categóricas), ou seja, para variáveis das classes fatore ou caracteres. Nestes gráficos, geralmente obsevamos a quantitade de vezes que o fator ocorre nos dados (sua frequência absoluta) ou suas frequências relativas (a porcentagem).


```{r}
# observar as frequências dos tipos de dieta nos dados de sps
# primeiro descobre as frequências:
t.dieta <- table(sps$dieta)

barplot(t.dieta, ylab="número de espécies", main="Dieta das espécies")
```

### Gráficos de pontos

Os gráficos **Cleverland Dotplot** são muito usados para ver a

### Histogramas

Histogramas são usados para variávies numéricas e servem para vermos a forma da distribuição dos dados:

```{r}

```



### Boxplots
outliers

### Gráficos quantil-quantil
normalidade

## Gráficos: Duas variáveis

### plot

## pairs - correlações




# Criação e edição de gráficos







# Material de Apoio
 
 dar exemplos de pacote lattice e ggplot2  
 link para tutorial graphics parameters
 
 
 
# Exercícios!

### 1. Para gerar uma amostra de 10.000 números de uma distribuição Normal com média 30 e desvio padrão 7, utilize o comando:
```{r}
vnormal = rnorm(10000, 30, 7)
```

- Qual o somatório das observações no vetor 'vnormal' que são maiores que 44? E maiores que 51?  
- Como você excluiria a maior observação do vetor 'vnormal'?  

### 2. Aninhamento de comunidades
O termo “aninhamento” (nesting) é usado para a situação em que comunidades mais pobres em espécies são um subconjunto das comunidades mais ricas. Uma análise exploratória rápida de aninhamento é ordenar as linhas e as colunas de uma matriz binária de ocorrência das espécies por comunidades.

1. Crie um objeto da classe `matrix` com a matriz de ocorrência de mamíferos em topos de [montanhas](http://ecologia.ib.usp.br/bie5782/lib/exe/fetch.php?media=dados:gbmam93.csv.pdf) (retire a extensão pdf). (DICA: a função read.table retorna um data frame. Use a função as.matrix para mudar a classe para matriz.)  
2. Use o ordenamento por indexação para criar uma matriz com as comunidades por ordem decrescente de espécies, e as espécies por ordem decrescente de frequência de ocorrência. (OUTRA DICA: lembre-se da função apply!).  
3. A matriz resultante tem sinais de aninhamento? Por que?  

```{r resultado, echo=FALSE}
mont <- read.csv2("montanha.csv",dec=".",header = T,row.names = 1)
mont <-as.matrix(mont)
tot.sp <- apply(mont,1,sum)
tot.loc <- apply(mont,2,sum)
mont[order(tot.sp, decreasing = T) , order(tot.loc, decreasing =T)]
```
 
 
 <!-- continuar exercícios -->
 