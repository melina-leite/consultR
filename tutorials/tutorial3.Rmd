---
title: 'Roteiro 3 - Modelos Estat√≠sticos'
author: "Melina Leite"
date: "Departamento de Ecologia IB-USP"
output:
  rmdformats::readthedown:
    highlight: kate
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, echo = F, message = F, cache = F}
knitr::opts_chunk$set(comment = NA, results = 'hide', message = FALSE, eval=FALSE, cache=FALSE, warning=FALSE)

#global options que vieram no rmdformats de html
library(knitr)
library(rmdformats)
library(lattice)
options(max.print="75")
opts_knit$set(width=75)
```

```{r setwd, echo=F}
setwd("../consultR/tutorials")
```

Neste roteiro usaremos um exemplo inicial para discutir algumas quest√µes referentes √† infer√™ncia estat√≠stica, distribui√ß√µes de probabilidade, modelos estat√≠sticos e testes de hip√≥teses. Este roteiro n√£o pretende se aprofundar nestes temas, principalmente em rela√ß√£o aos aspectos formais e te√≥ricos da Estat√≠stica. N√≥s enfocaremos na quest√£o pr√°tica de entender como funcionam os modelos estat√≠sticos lineares, como faz√™-los, se nossos dados atendem √†s premissas destes e como interpretar os resultados destas an√°lises no R.

Este roteiro nem de longe substitui um bom estudo/curso sobre estat√≠stica b√°sica. Recomendamos fortemente a leitura do livro ["Estat√≠stica sem matem√°tica"](http://www.editoraplanta.com.br/EsM.htm), para aprender mais sobre estat√≠stica de forma intuitiva e fluida.


# Um problema

Vamos come√ßar esbo√ßando um problema inicial. Um pesquisador prentende medir a altura de √°rvores em uma floresta, pois ele tem algumas id√©ias sobre a **distribui√ß√£o de frequ√™ncias de alturas** e gostaria de **inferir** sobre algumas caracter√≠sticas das √°rvores. √â humanamente imposs√≠vel medir todas as √°rvores da floresta (**popula√ß√£o**), ent√£o ele pega uma **amostra aleat√≥ria** de √°rvores para prover as informa√ß√µes. Vamos ajudar esse pesquisador a analisar seus dados.

## Infer√™ncia estat√≠stica
Infer√™ncia estat√≠stica nada mais √© do que tentar fazer afirma√ß√µes sobre as caracter√≠sticas de uma **popula√ß√£o**, com base em informa√ß√µes dadas por **amostras**. Para isso, n√≥s vamos estimar os par√¢metros reais da popula√ß√£o atrav√©s de nossa amostra. Nesse caso o termo **popula√ß√£o** √© qualquer conjunto de elementos que voc√™ est√° observando, ou seja, estamos nos referindo a uma popula√ß√£o de n√∫meros que podem ou n√£o estar associados a uma popula√ß√£o biol√≥gica. **Amostra** √© qualquer subconjunto desta popula√ß√£o.

A altura m√©dia das √°rvores da floresta √© um **par√¢metro** que n√£o sabemos e ent√£o usaremos a amostra para **estimar** este par√¢metro. Podemos estimar a **distribui√ß√£o** das alturas na amostra e esperamos que esta reflita a distribui√ß√£o de altura de todas as √°rvores. Temos ent√£o como calcular os descritores da amostra e como estimativa dos descritores reais da popula√ß√£o. Por√©m, afirmar algo sobre uma popula√ß√£o baseado em uma amostra pode ser perigoso e nos fazer cometer erros. 

O que n√≥s fazemos ent√£o √© ajustar um modelo te√≥rico de distribui√ß√£o de probabilidades nos nossos dados para poder inferir sobre os par√¢metros da popula√ß√£o. Por exemplo, observando o histograma da distribui√ß√£o das alturas, os valores estimados da m√©dia e vari√¢ncia dos dados, modelamos a 'altura das √°rvores' como uma **vari√°vel aleat√≥ria** que tem uma **distribui√ß√£o de probabilidades normal** com m√©dia (Œº) e desvio padr√£o (œÉ).

Baixe o arquivo de dados [arvores.csv](https://www.dropbox.com/s/wthkhgox6ehbo4u/arvores.csv?dl=0) 
```{r dados importados, echo=F}
arv <-read.table("../data/arvores.csv", sep=";", header=T)

```

```{r dados}
# dados da altura das √°rvores coletadas pelo pesquisador
arv <-read.table("arvores.csv", sep=";")

hist(arv$alt)

mean(arv$alt)
var(arv$alt)
sd(arv$alt)
```


## Definindo vari√°veis aleat√≥rias
A vari√°vel aleat√≥ria X √© uma vari√°vel que tem um valor √∫nico (determinado aleatoriamente) para cada resultado de um experimento (lembre-se esse termo veio da teoria de probabilidade). A palavra aleat√≥ria indica que em geral s√≥ conhecemos aquele valor depois do experimento ser realizado.

Exemplos de vari√°veis aleat√≥rias:

a. Altura das √°rvores de uma floresta (!!)

b. N√∫mero de presas capturadas por um predador em um determinado dia;

c. Comprimento de um peixe adulto selecionado aleatoriamente.

As vari√°veis aleat√≥rias podem ser discretas ou cont√≠nuas.

**Vari√°vel aleat√≥ria discreta**: n√∫mero ou a quantidade observada na unidade experimental ou tentativa.  
- Representada por n√∫meros inteiros (0, 1, 2, 3, 4...);  
- N√£o pode conter n√∫meros negativos;  
- N√∫mero finito de possibilidades;  
- Podemos achar a probabilidade de cada evento.  

**Vari√°vel aleat√≥ria cont√≠nua**: usualmente medidas cont√≠nuas como peso, altura, dist√¢ncia, pH, biomassa, etc.  
- Representada por n√∫meros n√£o inteiros (1.3, - 1.54, - 1.7);  
- Pode conter n√∫meros negativos;  
- N√∫mero infinito de possibilidades;  
- Probabilidade de cada evento √© zero.

Estas vari√°veis aleat√≥rias ter√£o sempre uma **fun√ß√£o de probabilidade** associando cada poss√≠vel valor da vari√°vel (X) √† sua probabilidade de ocorr√™ncia P(X). Quando conhecemos todos os valores de uma vari√°vel aleat√≥ria, juntamente com suas respectivas probabilidades, temos uma **distribui√ß√£o de probabilidades**. As distribui√ß√µes de probabilidades discretas s√£o conhecidas como fun√ß√£o massa de probabilidade, enquanto que distribui√ß√µes de probabilidade cont√≠nuas s√£o conhecidas como fun√ß√£o de densidade de probabilidade. A diferen√ßa est√° no fato de que nas distribui√ß√µes discretas temos a probabilidade para cada valor de X, enquanto que nas distribui√ß√µes cont√≠nuas temos a probabilidade para um intervalo.

Hoje em dia voc√™ pode usar diversas distribui√ß√µes de probabilidades que melhor se ajustam aos seus dados (e at√© mesmo fazer testes que n√£o levam em conta estas distribui√ß√µes te√≥ricas, mas n√£o veremos isso aqui). Falaremos brevemente, sem mencionar os aspectos matem√°ticos de algumas distribui√ß√µes mais usadas por bi√≥logos. Para saber mais sobre estas distribui√ß√µes recomendo ler a apostila ["Estat√≠stica aplicada √† ecologia usando o R"](https://cran.r-project.org/doc/contrib/Provete-Estatistica_aplicada.pdf), de onde vieram algumas informa√ß√µes deste roteiro.


# Algumas Distribui√ß√µes de Probabilidade

## Bernouli

Quando jogamos uma moeda, os resultados poss√≠veis s√£o cara ou coroa. Se a moeda n√£o √© viciada, a probabilidade de dar √© cara a mesma probabilidade de dar coroa, ou seja 50%. Neste caso estamos interessados na ocorr√™ncia de **sucesso** ou **fracasso**. Assim, podemos definir uma vari√°vel aleat√≥ria X que assume apenas dois valores: 1 se ocorrer sucesso, 0 se ocorrer fracasso. Seu √∫nico par√¢metro ser√° _p_ que indica a probabilidade de sucesso. 

Seu valor esperado na distribui√ß√£o ser√° o pr√≥prio _p_

E[X] = p

e a sua vari√¢ncia

var[X] = p(1-p)


Usamos a nota√ß√£o X ~ Bernouli(p) para indicar esta vari√°vel. 

#### Exemplo

Vejamos um gr√°fico da fun√ß√£o de probabilidade da Bernoulli com p=0.3:

```{r bernoulli}
plot(dbinom(0:1, size=1, prob=0.3), 
    xlim=c(0,3), ylim=c(0,1), 
    xlab="resultados previstos",
    ylab="Probabilidade", 
    main="Distribui√ß√£o Bernoulli p=0.3",
    type="h", xaxt="n")
axis(1, at=c(1,2), labels = c(0,1))
```

Muitos dos dados de presen√ßa/aus√™ncia de esp√©cies por exemplo, s√£o modelados como uma distribui√ß√£o de Bernoulli. 

## Binomial

Agora imagine que repetimos um ensaio de bernoulli _n_ vezes. Esta amostra ser√° constitu√≠da de uma sequ√™ncia de sucessos e fracassos.
A distribui√ß√£o binomial √© a distribui√ß√£o de probabilidade **discreta** do **n√∫mero de sucessos** em uma sequ√™ncia de **n** tentativas tal que:  

i) as tentativas s√£o independentes;   

ii) cada tentativa resulta apenas em duas possibilidades, sucesso ou fracasso; e   

iii) a probabilidade de cada tentativa, *p*, permanece constante.   

Se X ~ Bin(n, p), isto √©, X √© uma vari√°vel aleat√≥ria distribu√≠da binomialmente, ent√£o o valor esperado de X √©:

E[X] = np 

e a vari√¢ncia √©

var[X] = np(1-p)

#### Exemplo

H√° uma probabilidade de 0,30 de um girino, ao forragear em um corpo d‚Äô√°gua, ser predado por uma larva de odonata. Vamos desenhar o histograma das probabilidades de que, dentre seis girinos que est√£o forrageando no corpo d‚Äô√°gua, 0, 1, 2, 3, 5 ou 6 sejam predados.

```{r binomial}
plot(y=dbinom(0:6, size=6, prob=0.3), 
    x=c(0:6),
    xlab="N√∫mero de girinos predados",
    ylab="Probabilidade", 
    main="Distribui√ß√£o binomial:  n=6, p=0.3",
    type="h")
```

## Poisson

Na teoria da probabilidade e na estat√≠stica, a distribui√ß√£o de **Poisson** √© uma distribui√ß√£o de probabilidade discreta. Expressa a probabilidade de uma s√©rie de eventos ocorrem em um per√≠odo fixo de tempo, √°rea, volume, quadrante, etc. Esta distribui√ß√£o segue as mesmas premissas da distribui√ß√£o binomial:    

i) as tentativas s√£o independentes;   

ii) a vari√°vel aleat√≥ria √© o n√∫mero de eventos em cada amostra; e   

iii) a probabilidade √© constante em cada intervalo.

Se X ~ Pois(Œª), isto √©, X √© uma vari√°vel aleat√≥ria com distribui√ß√£o Poisson, ent√£o o valor esperado de X √©

E[X] = (Œª)

e a vari√¢ncia √©

var[X] = (Œª)

#### Exemplo

Suponha que um pesquisador registrou o n√∫mero de visitas √† flor de uma planta durante um per√≠odo de 15 minutos. O n√∫mero m√©dio de borboletas que visitam no per√≠odo de 15 minutos √© 10 (Œª). Vamos determinar a probabilidade de que cinco borboletas visitem a flor em 15 minutos. A probabilidade de uma borboleta visitar √© a mesma para quaisquer dois per√≠odos de tempo de igual comprimento. Abaixo o histograma dessa distribui√ß√£o de probabilidade.

```{r poisson}
#probabilidade de que 5 borboletas visitem a flor:
dpois(5,10)

# histograma da distribui√ß√£o
plot(dpois(seq(1,20, by =1), lambda = 10), type ="h",
     xlab = "N√∫mero de visitas", 
     ylab = "Probabilidade", 
     main = "Fun√ß√£o massa de probabilidade")
```


## Normal

A distribui√ß√£o normal √© uma das mais importantes distribui√ß√µes com probabilidades cont√≠nuas. Esta distribui√ß√£o √© descrita pelos par√¢metros m√©dia (Œº) e desvio padr√£o (œÉ), ou seja, conhecendo-se estes par√¢metros consegue-se determinar qualquer probabilidade em uma distribui√ß√£o Normal.  

A import√¢ncia da distribui√ß√£o normal como um modelo de fen√¥menos quantitativos √© devido em parte ao [**Teorema Central do limite **](https://pt.wikipedia.org/wiki/Teorema_central_do_limite). O teorema afirma que "toda soma de vari√°veis aleat√≥rias independentes de m√©dia finita e vari√¢ncia limitada √© aproximadamente Normal, desde que o n√∫mero de termos da soma seja suficientemente grande". Independentemente do tipo de distribui√ß√£o da popula√ß√£o, na medida em que o tamanho da amostra aumenta, a distribui√ß√£o das m√©dias amostrais tende a uma distribui√ß√£o Normal.

Vari√°veis aleat√≥rias com distribui√ß√£o aproximadamente normal apresentam as seguintes propriedades:  

‚Äì Metade (50%) est√° acima (e abaixo) da m√©dia  

‚Äì Aproximadamente 68% est√° dentro de 1 desvio padr√£o da m√©dia  

‚Äì Aproximadamente 95% est√° dentro de 2 desvios padr√µes da m√©dia  

‚Äì Virtualmente todos os valores est√£o dentro de 3 desvios padr√µes da m√©dia  

#### Exemplo
Qual √© a probabilidade de que um peixe capturado aleatoriamente tenha 20,15 cm ou mais, sabendo que a m√©dia da popula√ß√£o √© 17,1 cm e o desvio padr√£o √© de 1,21 cm? Vamos descobrir usando a fun√ß√£o `pnorm` e tra√ßar o histograma dessa distribui√ß√£o de probabilidade.

```{r normal}
# calculando a probabilidade de ter um peixe maior ou igual a 20.15
prob <- pnorm(q = 20.15, mean = 17.1, sd = 1.21, lower.tail = F)
prob

#histograma
x<-seq(13, 22, 0.1)
y=dnorm(x, mean = 17.1, sd=1.21)
plot(x, y, type="l", lwd=2, col="red", 
     ylab = "Probabilidade",
     xlab= "Comprimento dos peixes",
     main ="Fun√ß√£o densidade de probabilidade")
abline(v = 17.1, lty=2)
abline(v = 20.15, lty=3)
```


# Voltando ao nosso problema


Voltamos ent√£o com nosso exemplo sobre as alturas das √°rvores de duas esp√©cies em uma floresta. N√≥s modelamos estes dados como uma vari√°vel aleat√≥ria de distribui√ß√£o normal. Por√©m, n√≥s coletamos os dados de duas esp√©cies diferentes. Ser√° que a altura m√©dia de uma esp√©cie nessa floresta √© diferente da altura m√©dia da outra esp√©cie? Ou seja, ser√° que as esp√©cies pertencem a uma mesma distribui√ß√£o e as diferen√ßas encontradas s√£o devido ao acaso ou ser√° que cada esp√©cie √© uma vari√°vel aleat√≥ria com m√©dias diferentes?

Para inspecionar nossas d√∫vidas, vamos desenhar as distribui√ß√µes de frequ√™ncias das alturas separadamente para cada esp√©cie:

```{r histograma}
histogram(~alt|sp, 
          data = arv,
          layout = c(1,2),
          strip=F,
          strip.left=T)
```


A diferen√ßa entre as m√©dias observadas das esp√©cies √©:
```{r dif medias}
mean(arv$alt[arv$sp=="sp2"]) - mean(arv$alt[arv$sp=="sp1"])
```

Ent√£o, se afirmarmos que n√£o h√° diferen√ßa entre as alturas das esp√©cies, podemos estar incorrendo no erro chamado de **tipo 2**, de que h√° diferen√ßas. Se afirmarmos que h√° diferen√ßa entre as alturas, ou seja rejeitamos a hip√≥tese nula, podemos incorrer no erro do **tipo 1**, dizendo que h√° diferen√ßas quando n√£o h√°. Como decidir?

Vamos construir nossas hip√≥teses:

**H0** - n√£o h√° diferen√ßa entre as alturas das duas esp√©cies. A m√©dia da altura da esp√©cie 1 √© igual √† m√©dia da altura da esp√©cie 2 e a diferen√ßa observada se deve ao acaso.  

**H1** - h√° diferen√ßa entre as alturas das duas esp√©cies. A m√©dia da altura da esp√©cie 1 √© diferente da m√©dia da altura da esp√©cie 2.

Vamos definir os erros:

Ao escolher por uma das hip√≥teses, quais erros podemos cometer?

**ERRO DO TIPO I**: rejeitar a hip√≥tese nula dada que ela √© verdadeira.

**ERRO DO TIPO II**: aceitar a hip√≥tese nula dado que ela √© falsa.

Podemos calcular as probabilidades de cada um destes errros:

Œ±: probabilidade do erro do tipo I

Œ≤: probabilidade do erro do tipo II

A quantidade Œ± tamb√©m √© conhecida como **n√≠vel de signific√¢ncia do teste.**


Para sabermos se de fato uma √°rvore √©, em m√©dia, mais alta que a outra, procederemos utilizando um teste de hip√≥teses, neste caso o **teste t**. Este teste basicamente ir√° contrastar a probabilidade de que a diferen√ßa que voc√™ encontrou nas m√©dias das alturas das duas esp√©cies pode se considerada devido ao acaso ou n√£o. Ou seja, nossa pergunta √© qual √© a probabilidade de que as duas amostras pertencem √† mesma popula√ß√£o de medidas? Com que frequ√™ncia esperar√≠amos amostras com m√©dias t√£o ou mais diferentes do que a de nossas amostras se elas realmente vieram da mesma popula√ß√£o de medidas? Vamos ver se podemos ou n√£o rejeitar a hip√≥tese nula (de que a diferen√ßa √© ao acaso), baseado em alguma probabilidade de estarmos cometendo algum erro em nossa afirma√ß√£o de que a hip√≥tese nula √© verdadeira.

#### Graus de liberdade

Tamanho da amostra: 100 √°rvores
Par√¢metros estimados: m√©dia e vari√¢ncia: 2

Graus de liberdade: 100-2

Antes de partirmos para o teste t em si, precisamos entender o conceito de **graus de liberdade**. Para encontrar a probabilidade associda com qualquer valor em partircular de uma estat√≠stica (no nosso exemplo, a estat√≠stica t), precisamos conhecer quantas observa√ß√µes independentes foram usadas para calcul√°-las. Usualmente se diz que os graus de iberade dos testes estat√≠sticos s√£o o n√∫mero de observa√ß√µes independentes menos o n√∫mero de par√¢metros estimados. Em nosso exemplo, t√≠nhamos 100 √°rvores amostradas e estimamos a m√©dia e o desvio padr√£o para construir a distribui√ß√£o de resultados esperados quando a hip√≥tese nula era verdadeira. Portanto, o grau de liberdade para a estat√≠stica t em nosso exemplo √© 100-2 = 98.

## Teste t

N√£o entraremos em detalhes de como se calcula a estat√≠stica t e como √© a sua distribui√ß√£o de probabilidades (recomendo ver na [wikipedia](https://pt.wikipedia.org/wiki/Distribui%C3%A7%C3%A3o_t_de_Student)). O importante a saber aqui √© que tendo as duas amostras modeladas como uma distribui√ß√£o normal, calculamos a estat√≠stica t e com um certo valor de graus de liberdade, n√≥s podemos recorrer √†s tabelas da distribui√ß√£o t para ver qual a probabilidade de se obter aquele valor que obtivemos dada que a hip√≥tese nula √© verdadeira. Se esta probabilidade for muito pequena, a chance de estarmos caindo no erro do tipo 1 √© pequena.

No R, a fun√ß√£o usada para fazer um teste t √© `t.test`. 

```{r teste t}
t.test(arv$alt~arv$sp, var.equal=T)
#o argumento var.equa=T diz que as vari√¢ncias das duas esp√©cies s√£o as mesmas
# podemos fazer o teste com a premissa de que as vari√¢ncias n√£o sejam iguais,
# usando var.equal=F, isso vai "consumir" graus de liberdade.
```

Vamos interpretar este resultado: temos o valor de t calculado e os graus de liberade (j√° calculado pela gente antes). Com estes 2 valores, o que o R faz √© calcular a probabilidade de que a hip√≥tese nula seja verdadeira. Esse √© o **valor-p**, que neste exemplo deu um valor beem pequeno.
Vemos ent√£o que podemos rejeitar H0, com uma probabilidade muito baixa de estarmos incorrendo no erro de tipo 1, e desta forma acreditamos que as esp√©cies de √°rvores tenham distribui√ß√µes de alturas diferentes (m√©dias diferentes).

 
O teste t possui tr√™s variantes b√°sicas: a mais usada √© normalmente chamada de **teste t para amostras independentes**, e permite a compara√ß√£o de duas m√©dias (a que acabamos de fazer) (mais roteiros [aqui](http://statistic-on-air.blogspot.com.br/2009/07/two-sample-students-t-test-1.html) e [aqui](http://statistic-on-air.blogspot.com.br/2009/07/two-sample-students-t-test-2.html) ); o **teste t para uma amostra** compara uma m√©dia com um valor fixo (roteiro [aqui](http://statistic-on-air.blogspot.com.br/2009/07/one-sample-students-t-test.html) ); e o **teste t pareado** (ou teste t para amostras dependentes) compara m√©dias de unidades amostrais dependentes aos pares (roteiro [aqui](http://statistic-on-air.blogspot.com.br/2009/07/paired-students-t-test.html) ). Todos estas varia√ß√µes do teste t podem ser executadas no R pela fun√ß√£o `t.test`, e o uso do teste t pareado e do teste t para uma amostra pode ser ativado com o uso dos argumentos `paired` e `mu`, respectivamente. Para saber mais como realizar estes testes no R, veja o cap√≠tulo 3 da apostila [Introdu√ß√£o ao uso do software R para as Ci√™ncias Biol√≥gicas](https://cantinhodor.files.wordpress.com/2015/03/introduc3a7c3a3o-ao-software-r-para-biologia-marcos-vital-ufal-marc3a7o-2015.pdf).

Recomendo tamb√©m este [roteiro unicaulda de teste t](http://daniellakens.blogspot.com.br/2016/03/one-sided-tests-efficient-and-underused.html), que explica tamb√©m a diferen√ßa entre um teste unicaudal e bicaudal. No teste unicaudal sua hip√≥tese tem uma dire√ß√£o definida para a diferen√ßa entre as m√©dias, por exemplo, esperamos que a sp1 seja maior do que a esp√©cie 2. No teste bicaudal (o que acabamos de fazer), a hip√≥tese diz respeito apenas se h√° diferen√ßa entre as m√©dias e n√£o qual √© maior.


# Modelos lineares

E se tiv√©ssemos na verdade 3 esp√©cies de √°rvores para compararmos as alturas? Acabamos de ver que o teste t serve apenas para comparar duas amostras. O que chamamos de modelos lineares √© uma grande fam√≠lia de modelos estat√≠sticos que modelam uma rela√ß√£o linear entre a vari√°vel dependente (Y) e a(s) vari√°vel(is) independente(s). Nesta fam√≠lia encontra-se o teste t que acabamos de ver, a An√°lise de Vari√¢nci (ANOVA), a regress√£o, etc.

Chamamos de **Modelos Lineare Gerais** (LMs), aqueles que possuem como premissa a vari√°vel dependente Y como de distribui√ß√£o Normal, e de **Modelos Lineares Genearlizados** (GLMs) os que assumem outros tipos de distribui√ß√£o para a vari√°vel dependente (como a Binomial e Poisson). No R, a fun√ß√£o que usamos para estes modelos s√£o `lm` e `glm` (h√° alguns mais espec√≠ficos como o pr√≥rpio `t.test` e o `aov` para ANOVA). O R lida com todos os modelos lineares de maneira similar, e um detalhe importante √© que todas as an√°lises desta fam√≠lia devem ser salvas em um objeto, para seu resultado ser apresentado ap√≥s o comando `summary`.

√â importante lembrar que neste roteiro estamos lidando com modelos param√©tricos, ou seja, que **modela a vari√°vel de interesse como uma vari√°vel aleat√≥ria pertencente a uma certa distribui√ß√£o de probabilidades**. Existem outras abordagens estat√≠sticas n√£o-param√©tricas que fazem testes que n√£o tem como premissa a distribui√ß√£o de probabilidades. Veja um exemplo de **teste t n√£o param√©trico** neste [roteiro](http://ecologia.ib.usp.br/bie5782/doku.php?id=bie5782:02_tutoriais:tutorial6:start). 

Mesmo fazendo parte de uma mesma fam√≠lia de modelos, nas sess√µes seguintes vamos separar os modelos lineares pelos nomes tradicionais das an√°lises: an√°lise de vari√¢ncia, regress√£o linear simples e an√°lise de covari√¢ncia. Depois, veremos alguns exemplos de GLMs aplic√°veis a dados ecol√≥gicos.


## ANOVA

Vamos ent√£o incluir no nosso exemplo inicial uma terceira esp√©cie amostrada (e vamos diminuir o n√∫mero de amostras por esp√©cie para ficar mais f√°cil de fazer os c√°lculos passo a passo):
```{r dados3}
alt.sp3 <- c(36.90076761,33.23131727,32.82767311,24.93410577,31.87626329,
         28.76824248,26.6436144,31.41238398,27.65383929,31.70425719,
         33.60752445,28.30263354,29.32210674,23.4790054,22.20793046,
         18.28797293,23.39044736,28.75820917,29.94344703,34.47430235,
         32.09820862,26.99845592,27.64858951,31.90557306,33.63236368,
         25.35966179,35.00885172,32.89125598,18.98802229,30.8516906,
         22.04191398,35.37232889,35.67150408,34.30257037,24.43038475,
         20.6274663,31.15717916,23.27023231,36.20568545,34.33068448,
         28.40769054,31.00578874,29.50989158,31.69915991,37.25975797,
         30.1279997,38.623371,35.36472829,29.88304259,31.00145491)

sp3 <- data.frame(alt=alt.sp3, sp=rep("sp3",50))
arv2 <- rbind(arv,sp3)

amostras <- seq(1,150,by=5)

arv3 <- arv2[ amostras, ]
```

Neste exemplo lidaremos com um modelo simples de anova chamado **_one way_ ANOVA**, porque lida apenas com uma vari√°vel independente categ√≥rica (fator). 

A ANOVA testar√° a hip√≥tese nula de que as m√©dias das alturas das 3 esp√©cies n√£o diferem. 

Faremos agora a ANOVA "na unha", para entendermos melhor cada passo da an√°lise e a interpreta√ß√£o de seus resultados para depois usarmos a fun√ß√£o do R que faz esta an√°lise diretamente.

### ANOVA na unha

Vamos calcular os valores da tabela de ANOVA. Come√ßando com os desvios quadr√°ticos, ou seja, quanto os dados desviam da m√©dia (id√©ia parecida com a vari√¢ncia). O ponto importante √© que essa varia√ß√£o √© aditiva e portanto, pode se decomposta. A varia√ß√£o total √© decomposta em varia√ß√£o relacionada ao tratamento (_entre grupos_), no nosso caso √†s esp√©cies, e uma varia√ß√£o interna dos grupos (chamada de erro). A estat√≠stica F √© a raz√£o entre essas varia√µes ap√≥s dividir cada uma delas pelos seus respectivos graus de liberdade. Complicou? Vamos fazer os c√°lculos e ver os gr√°ficos para ver se entendemos melhor:

A tabela de ANOVA que vamos construir √© essa:

![](../tutorials/images/tab_anova.png)

Primeiro vamos mudar a forma do nosso data frame para facilitar os comandos
```{r}
arv4 <- data.frame(sp1=arv3$alt[arv3$sp=="sp1"],
                   sp2=arv3$alt[arv3$sp=="sp2"],
                   sp3=arv3$alt[arv3$sp=="sp3"])
arv4

boxplot(arv4)
```
Vamos calcular a m√©dia geral, as m√©dias para cada esp√©cie, e as diferen√ßas entre a m√©dia geral e a m√©dia para cada esp√©cie, para chegar ao valor da soma dos quadrados total:
```{r}
media.geral <- mean(arv3$alt)
media.geral

medias.sps <- apply(arv4, 2, mean)
medias.sps

dif.geral <- arv4 - media.geral
ss.especies <- dif.geral^2
ss.especies

ss.total <- sum(ss.especies)
ss.total
```

Para calcular os desvios quadr√°ticos totais, n√≥s subtra√≠mos cada altura das √°rvores pela m√©dia geral e elevamos ao quadrado. Veja o gr√°fico:
```{r}
vetor.cor <- rep(1:3, each=10) #vetor de cores

plot(x = c(1:30), y = arv3$alt, ylim=c(10,40),
     pch=(rep(c(15,16,17), each=10)),
     col=vetor.cor,
     ylab="Vari√°vel Resposta", xlab="Observa√ß√µes",
     main="Varia√ß√£o total")
	for(i in 1:30)
	{
	lines(c(i,i),c(arv3$alt[i],mean(arv3$alt)),col=vetor.cor[i])
	}
	abline(h=media.geral)
```


Agora vamos fazer a somat√≥ria dos desvios quadr√°ticos dentro de cada grupo (ss.intra).

O gr√°fico para entender esse c√°lculo:
```{r}
vetor.medias<-rep(medias.sps, each=10)

plot(c(1:30), arv3$alt, ylim=c(10,40),
     pch=(rep(c(15,16,17),each=10)),
     col=vetor.cor,
     main="Varia√ß√£o Intra Grupos",
     ylab="Vari√°vel Resposta", xlab="Observa√ß√µes")
	for(i in 1:30)
	{
	lines(c(i,i),c(vetor.medias[i],arv3$alt[i]),col=vetor.cor[i])
	}
	lines(c(1,10),c(medias.sps[1],medias.sps[1]),col=1)
	lines(c(11,20),c(medias.sps[2],medias.sps[2]),col=2)
	lines(c(21,30),c(medias.sps[3],medias.sps[3]),col=3)
```

C√°lculo dos valores:
```{r}
medias.sps
ss.sp1=sum((arv4$sp1-medias.sps["sp1"])^2)
ss.sp1
ss.sp2=sum((arv4$sp2-medias.sps["sp2"])^2)
ss.sp2
ss.sp3=sum((arv4$sp3-medias.sps["sp3"])^2)
ss.sp3
ss.intra=ss.sp1+ss.sp2+ss.sp3
ss.intra
```

A soma dos quadrados entre grupos:
```{r}
plot(c(1:30), vetor.medias, ylim=c(10,40), 
  pch=(rep(c(15,16,17),each=10)),
  col=vetor.cor, 
  main="Varia√ß√£o Entre Grupos", 
  ylab="Vari√°vel Resposta", xlab="Observa√ß√µes")
 for(i in 1:30)
	{
	lines(c(i,i),c(vetor.medias[i],mean(vetor.medias)),col=vetor.cor[i])
	}
	abline(h=media.geral)
	points(c(1:30),arv3$alt, ylim=c(10,50), 
	       pch=(rep(c(0,1,2),each=10)), col=vetor.cor, cex=0.5)
```

```{r}
medias.sps
media.geral
ss.entre=10*sum((medias.sps-media.geral)^2)
ss.entre

#conferindo os c√°lculos
ss.intra+ss.entre
ss.total
```

C√°lculo do F
```{r}
# Desvios m√©dios
ms.entre=ss.entre/2
ms.intra=ss.intra/27
ms.entre
ms.intra

#F - raz√£o das vari√¢ncias
F.sps=ms.entre/ms.intra
F.sps
```

#### Distribui√ß√£o F

Vamos ver na distribui√ß√£o F qual a probabilidade de termos econtrado o valor `F.sps` ao acaso:
```{r}
curve(expr=df(x, 2,27),
      main="Distribui√ß√£o F de Fisher (df=2,27)", 
      xlab="Valor F",
      ylab="Densidade Probabil√≠stica (df)",
      xlim=c(2,12))
abline(v=F.sps, col="red")
abline(h=0, lty=2)

xf=seq(F.sps, 12, 0.01)
ydf=df(xf, 2, 27)
polygon(c(F.sps,xf),c(0,ydf),col="red")

text(x= 7,y=0.08,paste("pf(x) =",
     round(pf(F.sps,2,27,lower.tail=F),4)), 
     cex=0.8, col="red")
```

C√°lculo do P
```{r}
p.sps=pf(F.sps, 2, 27, lower.tail=FALSE)
p.sps
```

Para mais informa√ß√µes sobre o F e as compara√ß√µes com o teste t, veja esse [roteiro](http://daniellakens.blogspot.com.br/2016/04/one-sided-f-tests-and-halving-p-values.html).

### A tabela final

Colocando os dados calculados em nossa tabela de anova

![](../tutorials/images/tab_anova_final.png)

### ANOVA no R

A fun√ß√£o que constr√≥i esta tabela de ANOVA e faz o teste estat√≠stico √© a `aov`. Vamos comparar:

```{r aov}
anova.sps <- aov(alt~sp, data=arv3)
summary(anova.sps)
```

Agora n√≥s sabemos de ondem vem os n√∫meros nesta tabela e como foi calculado o P, certo?

### Testes √† posteriori

Perceba que a nossa hip√≥tese nula na ANOVA √© de que as 3 m√©dias n√£o diferem. Ao rejeit√°-la, ent√£o, n√≥s apenas sabemos que pelo menos duas das m√©dias s√£o diferentes entre si, mas n√£o sabemos quais s√£o.
Alguns estat√≠sticos dizem que uma an√°lise gr√°fica √©  suficiente para saber quais m√©dias diferem ou n√£o entre si (por exemplo os autores do livro Estat√≠stica sem Matem√°tica). Entretanto, h√° tamb√©m a possibilidade de se fazer testes √† posteriori que v√£o comparar as m√©dias das esp√©cies par a par. Vejamos aqui o mais utilizado **teste de Tukey HSD**, chamado pela fun√ß√£o `TukeyHSD`, que atua diretamente no objeto com o resultado da ANOVA:

```{r tukey}
TukeyHSD(anova.sps)

#revendo gr√°fico dos dados
stripchart( arv3$alt~arv3$sp,
           vertical = TRUE, pch = 16, 
           col = c("black", "red", "green"))

#boxplot
boxplot(arv4)
```

Nossa an√°lise ent√£o indicou que h√° diferen√ßas entre as m√©dias das alturas das √°rvore, mas que a esp√©cie 1 n√£o difere da esp√©cie 2, mas difere da esp√©cie 3, enquanto a esp√©cie 2 difere da esp√©cie 3. 

#### Outra maneira de fazer a ANOVA no R:

Talvez voc√™ se deparem com um c√≥digo no R que faz a ANOVA usando a fun√ß√£o `lm`, que √© mais gen√©rica e usada pra fazer qualquer an√°lise de modelo linear geral (distribui√ß√£o normal). Ent√£o vejamos:
```{r anova lm}
lm.anova.sp <- lm(alt~sp, data=arv3)
summary.aov(lm.anova.sp) #mesmo que o summary do aov

# mostra o resultado de forma um pouco diferente, consegue entender?
summary(lm.anova.sp) 
```

Vamos tentar interpretar o que esse segundo `summary` nos diz do modelo. A tabela de coeficientes tem tantas linha quanto param√™tros no modelo. No nosso caso n√≥s temos 3 par√¢metros que s√£o as m√©dias pra cada esp√©cie.
A primeira linha da tabela (intercept), √© a m√©dia do fator que vem primeiro em ordem alfab√©tica, no nosso caso indica a m√©dia da primeira esp√©cie. As outras duas linhas s√£o as diferen√ßas entre m√©dias da primeira esp√©cie (intercept) com a segunda e a terceira esp√©cie, ou seja n√£o s√£o os valores das m√©dias das esp√©cies. A estat√≠sticas calculadas em cada linha (Std. Error, t value e P), s√£o calculadas para o valor do coeficiente apresentando. Ent√£o, o valor de P na primeira linha indica se aquele coeficiente estimado √© diferente de zero. Na segunda linha, como estamos lidando com a diferen√ßa da m√©dia da esp√©cie 2 com a esp√©cie 1, o teste indica se essa diferen√ßa entre elas √© significativa. O mesmo para a linha da esp√©cie 3, o valor de p √© a diferen√ßa dela com a esp√©cie 1.


## Regress√£o linear simples

Vamos pensar agora se nossa vari√°vel independente (explicativa) fosse uma vari√°vel cont√≠nua, por exemplo a quantidade de nutrientes no solo. N√≥s criamos uma vari√°vel de quantidade de nutrientes (completamente fict√≠cia como todos os dados), e queremos agora saber se a quantidade de nutrientes no solo afeta a altura das √°rvores. Nossa hip√≥tese √© de que quanto mais nutrientes, mais alta a √°rvore pode ficar. 
Nesse caso, chamamos esse modelo linear classicamente como regress√£o. 

Inserindo os dados de quantidade de nutrientes:
```{r dados regr}
# criando a vari√°vel nutrientes
nutri <- c(1.09, 1.73, 1.49, 2.84, 3.08, 8.24, 8.67, 6.10, 8.37, 8.03,
           10.62, 14.26, 13.77, 14.81, 14.40, 17.27, 15.46, 18.66, 16.03,
           17.37, 26.80, 27.1, 29.09, 20.46, 24.51, 28.56, 24.87, 27.44,
           26.02, 22.94)

# ordenando arv3 por altura (para criar uma rela√ß√£o com nutrientes)
arv3 <-arv3[order(arv3$alt), ]

#colocando no data.frame de dados
arv3$nutri <- nutri
```

Agora vamos observar a rela√ß√£o entre a altura da √°vore e a quantidade de nutrientes no solo:
```{r plot regr}
plot(arv3$alt ~ nutri)
```

Vamos ent√£o modelar a rela√ß√£o e ver os resultados:
```{r mod regr}
alt.nutr <- lm(alt ~ nutri, data = arv3)
summary(alt.nutr)
```

Os resultados de uma regress√£o linear que rejeita a hip√≥tese nula s√£o comumente apresentados com uma representa√ß√£o gr√°fica que mostra os dados (em um gr√°fico de dispers√£o) e a equa√ß√£o (na forma de uma reta). Para adicionar a reta da equa√ß√£o ao gr√°fico criado pelo comando `plot`, basta, com o gr√°fico aberto, executar o comando `abline`, fazendo refer√™ncia ao objeto que cont√©m o resultado da regress√£o:

Vamos agora desenhar esta reta da regress√£o para entendermos melhor:
```{r plot regr2}
plot(arv3$alt ~ nutri)
abline(alt.nutr, col = "red") # reta da regress√£o

#reta da hip√≥tese nula de aus√™ncia de efeito dos nutrientes
abline(h = mean(arv3$alt), col = "blue", lty = 2)  
```

Os resultados do `summary` s√£o parecidos com os de uma ANOVA, mas conta com alguns detalhes a mais. No exemplo acima, a linha  do (Intercept) refere-se ao intercepto da equa√ß√£o linear (o **a**, na equa√ß√£o **y = a + bx**), e verifica a hip√≥tese nula de que ele seria igual a zero; de uma forma geral, n√≥s raramente nos preocupamos com a esta parte do resultado, pois o intercepto normalmente n√£o faz parte da nossa pergunta. J√° a linha debaixo, com o nome da vari√°vel explicativa (nutri), √© sempre do nosso interesse: ela verifica a **hip√≥tese nula de que o par√¢metro b da equa√ß√£o (inclina√ß√£o da reta) seja igual a zero**; ou seja, ao rejeitarmos a hip√≥tese nula n√≥s conclu√≠mos que de fato h√° uma rela√ß√£o estatisticamente significativa entre as duas vari√°veis, e que o efeito desta rela√ß√£o √© medido por este par√¢metro. Por fim, a interpreta√ß√£o da correla√ß√£o, que est√° representada no par√¢metro `Adjusted R-squared` tamb√©m √© importante, e mede o quanto da varia√ß√£o na vari√°vel resposta foi de fato explicada pela vari√°vel explicativa. 

Confuso? Ent√£o vejamos os resultados do exemplo acima: o teste rejeita a hip√≥tese nula de que a altura das √°rvores n√£o varia em fun√ß√£o da quantidade de nutrientes (o valor de _p_ foi menor do que 0.05). O resultado da regress√£o permite concluirmos que, em m√©dia, cada incremento de uma unidade de nutriente aumenta a altura em 0,58 (este √© o valor de **b** da equa√ß√£o). Por fim, o valor de **R¬≤ ajustado** nos diz que 76,3% da altura da √°rvore √© explicada pela quantidade de nutrientes do local.


## ANCOVA

Com os dados das √°rvores n√≥s testamos independentemente duas hip√≥teses: se a altura m√©dia das √°rvores era diferente para cada esp√©cie e se a altura das √°rvores dependia da quantidade de nutrientes no solo. Mas porque fazer estas an√°lises separadamente? Ambas as vari√°veis independentes podem influenciar na altura das √°rvores e, para isso, precisamos model√°-las em conjunto.

O modelo linear proposto abaixo √© muitas vezes chamado de ANCOVA, ou seja, An√°lise de Covari√¢ncia, que tem duas vari√°veis explicativas, uma categ√≥rica (no nosso caso a esp√©cie de planta) e uma cont√≠nua (os nutrientes).

```{r ancova aditivo}
alt.sp.nutr <- lm(alt ~ nutri + sp, data = arv3)
summary(alt.sp.nutr)
```

O modelo proposta acima √© o que chamamos de **modelo aditivo**, ou seja, as m√©dias das alturas das √°rvores podem diferir, mas o efeito do nutriente √© o mesmo para todas as esp√©cies. 

Vejamos o gr√°fico de resultados do modelo:
```{r ancova plot}
# tirando os valores de intercepto do modelo para cada especie
coef(alt.sp.nutr)
int.sp1 <- coef(alt.sp.nutr)[1]
int.sp2 <- coef(alt.sp.nutr)[1]+coef(alt.sp.nutr)[3]
int.sp3 <- coef(alt.sp.nutr)[1]+coef(alt.sp.nutr)[4]

plot(alt~nutri, data=arv3)

# reta de regress√£o para esp√©cie 1
abline(a=int.sp1, b=coef(alt.sp.nutr)[2], col="black")
# reta de regress√£o para sp 2
abline(a=int.sp2, b=coef(alt.sp.nutr)[2], col="red")
# reta de regress√£o para ps 3
abline(a=int.sp3, b=coef(alt.sp.nutr)[2], col="green")
```

Mas e se n√≥s acreditamos que as esp√©cies respondem de maneira diferente √† quantidade de nutrientes no solo? Ou seja, uma esp√©cie consegue crescer muito mais com a mesma quantidade de nutrientes do que as outras.

Para testar esse segundo modelo, inserimos ent√£o a _intera√ß√£o_ entre a vari√°vel qualitativa esp√©cie e a quantitativa nutrientes. Essa intera√ß√£o nada mais √© do que um novo fator resultado da multiplica√ß√£o entre as vari√°veis. Esse novo modelo √© chamado de **modelo com intera√ß√£o**. 

Existem duas nota√ß√µes de f√≥rmula diferentes para este modelo mas que significam a mesma coisa:
```{r ancova interativo}
alt.sp.nutr2 <- lm(alt ~ nutri + sp + nutri:sp, data=arv3)
summary(alt.sp.nutr2)

alt.sp.nutr3 <- lm(alt ~ nutri*sp, data=arv3)
summary(alt.sp.nutr3)
```

Vejamos o gr√°fico de resultado
```{r ancova graf}
# interceptos
int.sp1 <- coef(alt.sp.nutr2)[1]
int.sp2 <- coef(alt.sp.nutr2)[1] + coef(alt.sp.nutr2)[3]
int.sp3 <- coef(alt.sp.nutr2)[1] + coef(alt.sp.nutr2)[4]

#coeficientes
coef.sp1 <- coef(alt.sp.nutr2)[2]
coef.sp2 <- coef(alt.sp.nutr2)[2] + coef(alt.sp.nutr2)[5]
coef.sp3 <- coef(alt.sp.nutr2)[2] + coef(alt.sp.nutr2)[6]

plot(arv3$alt~nutri, col=rep(c("black", "red", "green"),each=10))

abline(a=int.sp1, b=coef.sp1, col="black", xlim=c(0.5))
abline(a=int.sp2, b=coef.sp2, col="red")
abline(a=int.sp3, b=coef.sp3, col="green")
```

Olhando a tabela de ANOVA deste modelo vemos que a intera√ß√£o (nutri:sp) n√£o foi significativa, e os nutrientes e as esp√©cies s√£o respons√°ves pela varia√ß√£o no na altura das √°rvores de maneira indepentende, ou seja, aditivamente:
```{r ancova test}
summary.aov(alt.sp.nutr3)
```

Se compar√°rmos o modelo aditivo com o interativo atrav√©s da `anova`, vemos que estes modelos nao s√£o diferentes significativamente, e portanto, n√≥s ficamos com o modelo mais simples (princ√≠pio da parcim√¥nia):
```{r}
anova(alt.sp.nutr3, alt.sp.nutr)
```


Portanto, o modelo mais parcimonioso para nossa ANCOVA √© o modelo aditivo, em que vemos a influ√™ncia dos nutrientes na altura das √°rvores assim como a diferen√ßa na altura sendo explicada pela esp√©cie de planta.

```{r selecao, echo=F}
m1 <- lm(alt ~ nutri * sp, data=arv3)
m2 <- lm(alt ~ nutri + sp, data=arv3)
m3 <- lm(alt ~ nutri , data=arv3)
m4 <- lm(alt ~ sp, data=arv3)
m5 <- lm(alt ~ 1, data=arv3)

library(bbmle)

AICtab(m1,m2,m3,m4,m5, base=T, weights=T)
```

# Modelos lineares generalizados

Os modelos estat√≠sticos que lidamos at√© agora tem como pressupostos a distribui√ß√£o Normal da vari√°vel resposta e homogeneidade de vari√¢ncias (tb conhecido como homocedasticidade). No entanto, em muitas situa√ß√µes a suposi√ß√£o de normalidade e var√¢ncia constante n√£o √© plaus√≠vel. Conseq√ºentemente, o uso de m√©todos que assumem a normalidade pode ser insatisfat√≥rio e aumentar a probabilidade de cometermos erros inferenciais (erros do Tipo I e II). √â a√≠ que entram os GLMs para modelar os dados quando a vari√¢ncia n√£o √© constante, e/ou quando os erros n√£o s√£o normalmente distribu√≠dos. Muitos tipos de dados t√™m erros n√£o normais. No passado, as √∫nicas maneiras capazes de lidar com esse problema eram a transforma√ß√£o da vari√°vel resposta ou a ado√ß√£o de m√©todos n√£o param√©tricos. Em GLM, assumimos que cada resultado da vari√°vel dependente Y seja gerado a partir de uma variedade de diferentes tipos de distribui√ß√µes que lidam com esse problema:  

- Poisson ‚Äì √∫teis para dados de contagem

- Binomial ‚Äì √∫teis para dados com propor√ß√µes
 
- Gamma ‚Äì √∫teis para dados mostrando um coeficiente constante de vari√¢ncia 
 
- Exponencial ‚Äì √∫teis com dados de an√°lises de sobreviv√™ncia

Existem muitas raz√µes para usar GLMs, em vez de regress√£o linear. Dados de presen√ßa-aus√™ncia s√£o (geralmente) codificados como 1 e 0, os dados proporcionais s√£o sempre entre 0 e 100%, e os dados de contagem s√£o sempre n√£o-negativos. GLMs usados para 0-1 e dados proporcionais s√£o normalmente baseados em distribui√ß√£o binomial e para dados de contagem as distribui√ß√µes de Poisson e binomial negativa s√£o op√ß√µes comuns. A m√©dia, Œº da distribui√ß√£o depende das vari√°veis independentes, X, e √© calculada atrav√©s de:

E[Y]  = ùúá =gùüè(ùëãùõΩ)

onde E (Y) √© o valor esperado de Y;  

XŒ≤ √© o preditor linear, uma combina√ß√£o linear de par√¢metros desconhecidos, Œ≤;  
g √© a fun√ß√£o de liga√ß√£o.  

O GLM consiste em tr√™s etapas:

1. Uma hip√≥tese sobre a distribui√ß√£o da vari√°vel resposta Yi. Isso tamb√©m define a m√©dia e a vari√¢ncia de Yi. (e.x., Distribui√ß√£o Poisson, Binomial, Gamma).

2. Especifica√ß√£o da parte sistem√°tica. Esta √© uma fun√ß√£o das vari√°veis explicativas. Y ~ a + bx 

3. A rela√ß√£o entre o valor m√©dio de Yi e a parte sistem√°tica. Esta √© tamb√©m chamada de fun√ß√£o de liga√ß√£o entre a m√©dia e a parte sistem√°tica. Ou seja, √© a fun√ß√£o que lineariza a regress√£o ( o g(xB) de cima).

Para cada tipo de distribui√ß√£o usada no GLM, temos uma fun√ß√£o de liga√ß√£o padr√£o (escrito em ingl√™s pois ser√£o os nomes dos argumentos no R):

<div align="center">
Distribui√ß√£o | link function
-------------|-------------------
normal | identity
poisson | log
binomial | logit
Gamma | reciprocal
</div>


## GLM Poisson 

Vamos testar se o n√∫mero de atropelamentos de uma estrada est√° relacionado com a dist√¢ncia a um Parque Nacional. Nossa vari√°vel resposta ser√° o n√∫mero de atropelamentos de um local e, portanto, vamos model√°-la como pertencente a uma distribui√ß√£o de Poisson. 

Dados
```{r, echo=F}
atrop <- read.table("../data/atropela.csv", header = T, sep = ";")
```

```{r pois dados}
atrop <- read.table("atropela.csv", header = T, sep = ";")
atrop
```

Vamos ver o gr√°fico de dispers√£o dos dados
```{r pois plot}
plot( atrop$TOT.N ~ atrop$D.PARK)
```

Para modelar os dados vamos ent√£o fazer um modelo GLM, colocando como distribui√ß√£o a Poisson, que tem por padr√£o a fun√ß√£o de liga√ß√£o "log"

```{r pois mod}
mod <- glm(TOT.N ~ D.PARK, data = atrop, 
           family = poisson)

summary(mod)
```

Vamos testar se este modelos √© diferente do modelo nulo
```{r pois test}
anova(mod, test = "Chisq")
```

Podemos ver que este modelo √© significativamente diferente do modelo nulo, portanto, a inclina√ß√£o da reta da rela√ß√£o entre atropelamentos e dist√¢ncia ao parque √© diferente de zero.

Vamos plotar  gr√°fico de resultado. Devemos lembrar que os coeficientes que aparecem no summary do modelos est√£o na escala do link function (nesse caso em log), por isso, antes de plotar a reta precisamos des-logaritmizar

```{r pois plot2}
coefi <- coef(mod)
coefi

plot(atrop$TOT.N~atrop$D.PARK,
     xlim = c(0,25000), ylim = c(0, 110),
     xlab = "Dist√¢ncia ao parque", ylab = "N√∫mero de atropelamentos")

#essa fun√ß√£o plota a curva do modelo, colocamos exp para voltar √† escala original dos dados
curve(exp(coefi[1] + coefi[2]*x), 
      xlim = c(0,25000), ylim = c(0, 110),
      xlab = "", ylab = "", 
      add=T, #adicionando a curva no plot j√° desenhado
      col="red")
```



## GLM Binomial


Vamos usar os dados de um trabalho que avaliou a quantidade de veados infectados com um parasita em cada local de amostragem. O pesquisador estava interessado em saber se a propor√ß√£o de animais infectados era influenciada pela quantidade de um tipo de vegeta√ß√£o (OpenLand) nos locais de amostra.

```{r echo=F}
veados <- read.table("../data/veados_parasitas.csv", header=T, sep=";")
```

```{r binom dados}
veados <- read.table("veados_parasitas.csv", header=T, sep=";")
str(veados)
summary(veados)
```

Nestes dados temos o n√∫mero de animais infectados, amostrados e a quantidade de habitat em cada local de amostragem.

A propor√ß√£o de animais infectados √© simplesmente o n√∫mero de infectados do totoal de animais.
```{r binom prop}
prop.veados <- veados$infectado/veados$amostrado
prop.veados
```

Vejamos o gr√°fico dessa rela√ß√£o:
```{r binom plot}
plot(prop.veados ~ veados$openland,
     ylim=c(0,1))
```

De fato parece que a propor√ß√£o de animais infectados diminui com o aumento da quantidade de 'openland' na paisagem.

Vamos fazer um modelo dos dados como pertencendo a uma distribui√ß√£o binomial, pois diz respeito ao n√∫mero de "sucessos" (infectados) em rela√ß√£o ao total de "tentativas" (animais amostrados). Usar os dados de propor√ß√£o como a vari√°vel dependente estaria errado, pois em dados de propor√ß√£o a distribui√ß√£o n√£o √© normal e a vari√¢ncia n√£o √© homog√™nea (ela √© muito maior em torno de 0.5).

Para modelar este dados a primeira coisa √© criar a vari√°ve Y como a combina√ß√£o entre o n√∫mero de infectados e n√£o infectados usando a fun√ß√£o `cbind` (junta colunas):
```{r binom cbind}
nao.infectado <- veados$amostrado- veados$infectado
y <- cbind(veados$infectado, nao.infectado)
```

Criando o modelo e vendo os resultados:
```{r binom mod}
mod.veado <- glm(y ~  openland, data=veados, family="binomial")
summary(mod.veado)
```

Vamos ver se nosso modelo √© significativamente diferente do modelo nulo:
```{r binom test}
anova(mod.veado, test = "Chisq")
```

Sim, podemos dizer que a quantidade de habitat 'openland' influencia na probabilidade dos animais serem infectados pelo parasita. Essa rela√ß√£o √© negativa, ou seja, quanto maior a quantidade de habitat, menores os n√≠veis de infec√ß√£o na popula√ß√£o de veados.

Plotando a curva do modelo
```{r binom plot2}
# salvando os coeficientes
coefs <- coef(mod.veado)
coefs

#lembre que estes coefs foram linearizados com a fun√ß√£o de liga√ß√£o
# para a binomial a link function √© a logit
# ent√£o temos que transformar os y no inverso do logit, a fun√ß√£o √© essa:
invlogit = function(x) return(exp(x)/(1+exp(x)))

plot(prop.veados ~ veados$openland,
     ylim=c(0,1))
#usando o invlogit para desenhar a curva:
curve(invlogit(coefs[1] + coefs[2]*x), add=T, col="red")
```



# Checando os modelos

At√© agora n√≥s fizemos nossos testes acreditando que as premissas deste estavam corretas e, portanto, os resultados dos testes confi√°veis. Por√©m, √© muito importante que n√≥s fa√ßamos a checagem das premissas antes de depois de ajustar m modelo e fazer o teste estat√≠stico. 

Por exemplo, podemos checar a homogeneidade de vari√¢ncia (homocedasticidade) e a normalidade da nossa vari√°vel de interesse fazendo testes espec√≠ficos, como veremos abaixo (mais exemplos [nesta apostila](https://cran.r-project.org/doc/contrib/Itano-descriptive-stats.pdf) ). Entretanto, √© importnate mencionar se sua amostra √© pequena, estes testes n√£o ser√£o capazes de rejeitar a hip√≥tese nula e portanto v√£o dizer que seus dados s√£o normais ou homog√™neos quando na verdade n√£o s√£o (erro tipo 2). Por isso, mesmo fazendo estes testes, checar o ajuste do modelo aos seus dados com gr√°ficos de diagn√≥stico √© crucial para que nos sintamos seguros de estarmos fazendo a infer√™ncia baseada na resposta dos testes dos modelos.

## Teste de normalidade

Um dos testes de normalidade muito utilizado √© o teste de Shapiro-Wilks (`shapiro.test`). Neste teste a hip√≥tese nula √© de que os dados s√£o normais, ou seja, se o resultado do teste der n√£o significativo significa que os dados n√£o se distanciam de uma distribui√ß√£o normal.

```{r shapiro}
shapiro.test(arv3$alt)
```

Portanto, podemos ficar um pouco mais seguros de ter modelado nossos dados de altura das √°rvores como tendo uma distribui√ß√£o normal. Mas n√£o nos esque√ßamos de que quando fizemos o teste t, n√≥s assumimos que a altura das √°rvores da sp1 e a altura da sp2 seguiam distribui√ß√£o normal, ent√£o vamos fazer para cada uma separadamente:
```{r shapiro2}
shapiro.test(arv$alt[arv$sp == "sp1"])
shapiro.test(arv$alt[arv$sp == "sp2"])
```

## Teste de homogeneidade de vari√¢ncias

Para saber se a vari√¢ncia dos dados √© homog√™nea entre os grupos (no caso as vari√°veis categ√≥ricas X) podemos fazer o **teste de Barltett** ou **Levene**. 

Teste de Bartlett:
```{r bartlett}
bartlett.test(arv3$alt~arv3$sp)
```

Teste de Levene:
```{r levene}
# carregando o pacote car que tem a fun√ß√£o do teste
library(car)

leveneTest(arv3$alt~arv3$sp)
```

O resultado n√£o significativo para ambos os testes diz que as vari√¢ncias das alturas das esp√©cies podem ser consideradas homog√™neas.

√ìtimo! Vamos agora checar o ajuste de nossos modelos lineares atrav√©s do diagn√≥stico dos res√≠duos.


## Checagem do modelo - Res√≠duos

Depois de ajustar um modelo aos dados n√≥s precisamos investigar qu√£o bem o modelo descreve os dados. Em particular, n√≥s dever√≠amos olhar se existe alguma tend√™ncia sistem√°tica na **qualidade do ajuste (goodness of fit) do modelo** (lembre-se, n√≥s ajustamos um modelo aos nossos dados e n√£o nossos dados ao modelo!). Para isso n√≥s trabalhamos com os **res√≠duos** do nosso modelo. 

Os **res√≠duos** s√£o os desvios que nosso dados observados tem do modelo ajustado. Lembre-se das figuras da "ANOVA na unha", onde tinham os valores das m√©dias para cada esp√©cie e linhas ligando os pontos dos dados √† este valor, essas linhas s√£o os desv√≠os em rela√ß√£o √† m√©dia, e portanto so res√≠duos do modelo. 

<div align="center">
RES√çDUO = Y(observado) - Y(dados ajustados)
</div>

Lembrando que nossa premissa de normalidade recai sobre os res√≠duos do modelo. Ou2 seja, s√£o os res√≠duos que precisam ter distribui√ß√£o normal. N√≥s checamos se a nossa vari√°vel resposta tem distribui√ß√£o normal (por exemplo com o teste acima) porque se ela tem, provavelmente seu res√≠duos tamb√©m o ter√£o. 

Podemos "pegar" os res√≠duos do nosso modelo usando a fun√ß√£o `residuals` ou `resid`.
```{r resid}
resid(anova.sps)
residuals(anova.sps) # o mesmo que a fun√ß√£o de cima
```

Outra coisa importante para se ver durante a checagem do modelo √© se existem dados (geralmente outliers) que est√£o influenciando mais o ajuste do modelo do que todos os outros. Numa regress√£o podemos pensar se existe alguns pontos que est√£o puxando a reta da regress√£o muito para baixo ou para cima, influenciando na estima√ß√£o dos coeficientes da regress√£o.

Para analisar tudo isso n√≥s usamos a fun√ß√£o `plot` com o objeto do nosso modelo. Esse comando nos retorna 4 gr√°ficos de diagn√≥stico. Vejamos nosso modelo da ANOVA:

```{r res anova}
# separando a √°rea gr√°fica em 4 espa√ßo para os 4 gr√°ficos
par(mfrow=c(2,2))

plot(anova.sps)
```

O primeiro gr√°fico plota a rela√ß√£o entre os res√≠duos do modelo (`resid(anova.sps)`) e os valores ajustados (3 m√©dias das alturas para as 3 esp√©cies). O plot identifica valores que destoam dos valores m√©dios. A linha vermelha que passa pr√≥xio ao zero dos res√≠duos indica se as vari√¢ncias dos res√≠duos est√£o homog√™neas. Quanto mais "reta" essa linha, melhor o diagn√≥stico

O segundo gr√°fico j√° √© conhecido (`qqnorm`) e mostra os ajustes dos quantis dos res√≠duos aos quantis de uma distribui√ß√£o normal padr√£o (Z, m√©dia = 0, vari√¢ncia = 1). Quanto mais alinhados com a reta do plot, mais os dados se ajustam √† normal. 

O terceiro gr√°fico √© uma varia√ß√£o do primeiro e compara os valores da raiz quadrada dos res√≠duos padronizados. Lembrando que os res√≠duos padronizados ser√£o **(residuo - media(residuo))/ sd(residuo)**.

O √∫ltimo gr√°fico nos mostra se n√≥s temos dados "influentes", ou seja que est√£o puxando as m√©dias das esp√©cies pra cima ou pra baixo e, portanto modificando os coeficiente dos modelos. Neste exemplo n√£o parece haver tend√™ncia de dados que estejam fazendo isso.

Vamos observar os gr√°ficos de diagn√≥stico para todos os modelos que criamos anteriormente

```{r res lms}
# regress√£o: alt ~ nutri
plot(alt.nutr)

# ANCOVA modelo aditivo: alt ~ nutri + sps
plot(alt.sp.nutr)

# ANCOVA modelo interativo: alt ~ nutri * sps
plot(alt.sp.nutr2)

# GLM poisson: atrop ~ dist.park
plot(mod)

# GLM binoimial: prop.infectado ~ openland
plot(mod.veado)

# para "desligar" o par inicial
par(mfrow=c(1,1))
```

Ent√£o, o que acharam dos ajustes dos outros modelos? Bom, ruim? Leva tempo para nos acostumarmos a olhar estes gr√°ficos e tirarmos conclus√µes de nossos ajustes. N√£o se desespere, procure ajuda vendo exemplos em livros e roteiros das an√°lises no R ("google it!").

_**Parab√©ns por chegar at√© aqui!!!**_

Para entender melhor os temas abordados nesse roteiro, al√©m dos links j√° passados, recomendo fortemente a leitura dos **Cap√≠tulos 8, 9, 10 e 13** (pelo menos) do livro **The R Book** do Crawley (se vc ainda n√£o baixou, [aqui o link](http://gen.lib.rus.ec/book/index.php?md5=e09db860b99f0710ec5746796c101d59) ). 


